<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>multilabel classification on Nick Sorros</title><link>https://nsorros.github.io/tags/multilabel-classification/</link><description>Recent content in multilabel classification on Nick Sorros</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 08 Jun 2022 10:10:30 +0300</lastBuildDate><atom:link href="https://nsorros.github.io/tags/multilabel-classification/index.xml" rel="self" type="application/rss+xml"/><item><title>Extreme Multilabel Classification in the Biomedical NLP Domain</title><link>https://nsorros.github.io/posts/extreme-multilabel-classification-talk/</link><pubDate>Wed, 08 Jun 2022 10:10:30 +0300</pubDate><guid>https://nsorros.github.io/posts/extreme-multilabel-classification-talk/</guid><description>This talk is based on a project I did for the Wellcome Trust for which I had to develop a model that assigns the most relevant of 29K MeSH tags.
If you want to read more about this topic, here are some additional blogs I have written
A neural network tagging biomedical grants Tagging biomedical grants with 29K tags Making an optimisation algorithm 10K times faster</description></item><item><title>Making an optimisation algorithm 10k times faster üèé</title><link>https://nsorros.github.io/posts/optimisation-10k-faster/</link><pubDate>Wed, 13 Apr 2022 10:10:30 +0300</pubDate><guid>https://nsorros.github.io/posts/optimisation-10k-faster/</guid><description>How we made our multilabel classification threshold optimizer converge in minutes instead of days Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied.</description></item><item><title>Tagging biomedical grants with 29K tags</title><link>https://nsorros.github.io/posts/tagging-biomedical-grants/</link><pubDate>Mon, 13 Dec 2021 10:10:30 +0300</pubDate><guid>https://nsorros.github.io/posts/tagging-biomedical-grants/</guid><description>In a previous post we spoke about a neural architecture we developed for classifying our grants with ~5K disease tags from the MeSH (Medical subject Headings) hierarchy. In this post we will touch on the techniques needed to scale to a model to classify all ~29K MeSH tags. Our dataset consists of 14M biomedical publications labelled with one or more MeSH tags (on average 12 tags per publications), so the challenge is both the thousands of outputs our model needs to recognise and the millions of examples it needs to learn from.</description></item></channel></rss>