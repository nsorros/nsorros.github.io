<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>docker on Nick Sorros</title><link>https://nsorros.github.io/tags/docker/</link><description>Recent content in docker on Nick Sorros</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 29 Jun 2022 10:10:30 +0300</lastBuildDate><atom:link href="https://nsorros.github.io/tags/docker/index.xml" rel="self" type="application/rss+xml"/><item><title>MLOps with SageMaker ‚Äî Part II</title><link>https://nsorros.github.io/posts/mlops-sagemaker-part2/</link><pubDate>Wed, 29 Jun 2022 10:10:30 +0300</pubDate><guid>https://nsorros.github.io/posts/mlops-sagemaker-part2/</guid><description>Customize train üê≥ In an earlier post we went through how to run a training script using sklearn, PyTorch or transformers with SageMaker by leveraging their preconfigured framework containers. The training scripts we used were self contained, meaning they only used the respective framework and python standard library. This meant we only had to worry about uploading our data and fetching our model from s3, and deciding the instance type we wanted to use.</description></item></channel></rss>