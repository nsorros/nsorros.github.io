<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Making an optimisation algorithm 10k times faster üèé | Nick Sorros</title><meta name=keywords content="optimisation,multilabel classification"><meta name=description content="How we made our multilabel classification threshold optimizer converge in minutes instead of days Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied."><meta name=author content><link rel=canonical href=https://nsorros.github.io/posts/optimisation-10k-faster/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nsorros.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nsorros.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nsorros.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://nsorros.github.io/apple-touch-icon.png><link rel=mask-icon href=https://nsorros.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Making an optimisation algorithm 10k times faster üèé"><meta property="og:description" content="How we made our multilabel classification threshold optimizer converge in minutes instead of days Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied."><meta property="og:type" content="article"><meta property="og:url" content="https://nsorros.github.io/posts/optimisation-10k-faster/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-13T10:10:30+03:00"><meta property="article:modified_time" content="2022-04-13T10:10:30+03:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Making an optimisation algorithm 10k times faster üèé"><meta name=twitter:description content="How we made our multilabel classification threshold optimizer converge in minutes instead of days Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://nsorros.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Making an optimisation algorithm 10k times faster üèé","item":"https://nsorros.github.io/posts/optimisation-10k-faster/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Making an optimisation algorithm 10k times faster üèé","name":"Making an optimisation algorithm 10k times faster üèé","description":"How we made our multilabel classification threshold optimizer converge in minutes instead of days Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied.","keywords":["optimisation","multilabel classification"],"articleBody":"How we made our multilabel classification threshold optimizer converge in minutes instead of days Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied.\nThe most naive approach to this problem is to apply a label when the probability is \u003e0.5, but this threshold can be higher (or lower). We can also decide to use a separate threshold for each label, and selecting the right one for each label is an optimization problem in its own right. This blog post is about how we sped up an implementation of an algorithm to solve this problem, and reduced its run time from 31 days to just five minutes.\nThe approach we followed is the one proposed by Pillar, et al. (2013) in their research paper ‚ÄúThreshold optimization for multi label classifiers‚Äù. The proposed algorithm for solving this optimization problem can be seen in the pseudo code-below:.\nThis algorithm effectively attends one label at a time and tries all possible thresholds for that label to find the threshold with the best micro f1. It does that iteratively (since a decision for one threshold might influence another) until no better threshold can be found for any label. Below is a naive implementation in python.\nhttps://github.com/nsorros/threshold_optimizer/blob/4d468f4da22d6586ca8699b8aaddd6f4caea84d8/optimize_threshold.py The code closely follows the pseudo code in the paper with the addition of the nb-thresholds parameter to limit the number of thresholds to scan thereby decoupling the run time from the dataset size used. Running this algorithm on two randomly sparse matrices takes 30s per label. This makes it prohibitively expensive for large label spaces, for example: assuming we need three iterations for the algorithm to converge and we are working with 30k labels it would take 30s x 30,000 x 3 ~ 31 days!\nSince we can‚Äôt usually wait 31 days just to decide which labels to apply after prediction, we needed to find a way to speed up this algorithm. The rest of this blog post focuses on just this problem. We‚Äôll be using a tool called line_profiler to inspect the slow moving parts of the algorithm and work towards making it faster.\nLine profiler was brought to my attention from the excellent book High performance python by Ian Ozvald and Micha Gorelick, which I highly recommend if you want to speed up your python code. All we need to do is install the line profiler pip install liner_profiler and add the @profile decorator in the functions we want to profile. Running our algorithm with it produces the following output:\nAs we can see most of the time is being spent inside the sklearn function f1_score. If we go ahead and profile it by adding the @profile decorator in the argmax function we get:\nAs it turns out, half of the time is being spent on checking that the data being passed are correct (see line 1547). This is super helpful in most cases, as it will throw an error if the data or flags do not make sense, but quite inefficient in our case, as we constantly pass the same data. Since we cannot disable this behavior we can simply write our own f1_score function.\nhttps://github.com/nsorros/threshold_optimizer/blob/2a3d198d3338de3c58437d154bafe9e07dd837a2/optimize_threshold.py This reduces runtime to 17s per label which is half our first attempt but still quite slow. If we profile again we get\nIn line 17, we see that we seem to have shifted the weight to sklearn‚Äôs multilabel_confusion_matrix. Let‚Äôs profile the multilabel_confusion_matrix function by adding the @profile decorator in the internal of sklearn‚Äôs code. You can find the location where site-packages are installed by running python -m site. The multilabel confusion matrix leaves in _classification.py inside metrics, full path sklearn/metrics/_classification.py.\nWe run into the same problem of spending most of the time checking that the y variables are correct, see line 483. Once more we can write our own implementation to avoid the checks.\nhttps://github.com/nsorros/threshold_optimizer/commit/7df2d45cda077662f2846a80edbce0c8a0383161 Using our own multilabel confusion matrix further reduces the time to 3s which is a 10x improvement so far. Let‚Äôs see what‚Äôs slowing us down now.\nWe can see that most of the time is being spent in the element-wise multiplication of two large sparse matrices. There is an inefficiency here which is not obvious at first glance: the multilabel confusion matrix recalculates a confusion matrix for each label even though we only alter the threshold for one label. A much more efficient way would be to calculate the multilabel confusion matrix outside this function and ultimately the for loop across labels and only change the entry for the label we explore. This requires us to calculate only one confusion matrix and I think at this point it is obvious that we are better off writing our own implementation.\nhttps://github.com/nsorros/threshold_optimizer/commit/7df2d45cda077662f2846a80edbce0c8a0383161 At this point our algorithm takes 0.46s per label which is a 65x speedup. In fact the whole optimization can finish in 5 hours which is acceptable. But, can we do better?\nA seemingly simple operation of choosing the relevant column, lines 31‚Äì32, seems to add up to a significant cost when running multiple times. Since those columns remain the same for the duration of trying different thresholds for one label inside argmax, we can easily improve by picking those columns before calling argmaxf1 and passing them in. https://github.com/nsorros/threshold_optimizer/commit/d8a2b8755bc244c22e8a1758b06ab597c6fff2db This change reduces the time to 0.17s per label which is a 176x speedup. This is beginning to be fast üí® but let‚Äôs see if we can push it further.\nEvery time we update the thresholds we recalculate the multilabel confusion matrix, line 87, and this is quite expensive. We can employ the same trick we did earlier inside f where we calculate only the confusion matrix that changes.\nhttps://github.com/nsorros/threshold_optimizer/commit/06cb7a127366aa9844b010e666f5e99190987a64 This takes us down to 0.02s per label which offers another 10x speedup for a total of 1500x. We could call it a day but let‚Äôs see if there is any other easy win.\nWe can see that a lot of time is being spent on selecting a column of a sparse matrix, lines 78‚Äì79. As it turns out these matrices are in CSR format which is quite efficient for a lot of common data science operations but not for selecting columns\nFortunately for us we can simply convert to CSC in load time and not have to worry about it moving on.\nhttps://github.com/nsorros/threshold_optimizer/commit/06cb7a127366aa9844b010e666f5e99190987a64 This switch makes the algorithm run on 0.003s per label which gives us a 10k final speedup. The whole algorithm will take approximately 5 minutes for 30k labels and a few hours for millions of labels which is super fast for the problem at hand. We can stop here but it‚Äôs worth saying that we have reached a limit of diminishing returns if we continue. Most of the time is being spent on highly optimized functions in numpy and scipy and even if we write our own and compile them with numba we will not manage to go any faster.\nThis blog has walked through the problem of how to optimize a naive implementation of an algorithm. Whilst the starting problem is not relevant to everyone, the techniques which I have used to speed up the implementation are super powerful, and can be applied to any problem.\nYou can find the whole code in this repository https://github.com/nsorros/threshold_optimizer and you can also follow the first 8 commits which introduce these changes.\n","wordCount":"1275","inLanguage":"en","datePublished":"2022-04-13T10:10:30+03:00","dateModified":"2022-04-13T10:10:30+03:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://nsorros.github.io/posts/optimisation-10k-faster/"},"publisher":{"@type":"Organization","name":"Nick Sorros","logo":{"@type":"ImageObject","url":"https://nsorros.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nsorros.github.io accesskey=h title="Nick Sorros (Alt + H)">Nick Sorros</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nsorros.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nsorros.github.io>Home</a>&nbsp;¬ª&nbsp;<a href=https://nsorros.github.io/posts/>Posts</a></div><h1 class=post-title>Making an optimisation algorithm 10k times faster üèé</h1><div class=post-meta><span title='2022-04-13 10:10:30 +0300 +0300'>April 13, 2022</span>&nbsp;¬∑&nbsp;6 min</div></header><div class=post-content><h2 id=how-we-made-our-multilabel-classification-threshold-optimizer-converge-in-minutes-instead-of-days>How we made our multilabel classification threshold optimizer converge in minutes instead of days<a hidden class=anchor aria-hidden=true href=#how-we-made-our-multilabel-classification-threshold-optimizer-converge-in-minutes-instead-of-days>#</a></h2><p>Multilabel classification is a common task in machine learning and Natural Language Processing (NLP). We approach it by training a model that can apply one or more labels to each new example that it sees. Since the model will output a probability for each of the labels, one of the parameters we can tweak to improve its performance (for example measured in micro f1) is the threshold probability at which a label is applied.</p><p>The most naive approach to this problem is to apply a label when the probability is >0.5, but this threshold can be higher (or lower). We can also decide to use a separate threshold for each label, and selecting the right one for each label is an optimization problem in its own right. This blog post is about how we sped up an implementation of an algorithm to solve this problem, and reduced its run time from 31 days to just five minutes.</p><p>The approach we followed is the one proposed by Pillar, et al. (2013) in their research paper ‚Äú<a href=https://pralab.diee.unica.it/sites/default/files/pillai_PR2013_Thresholding_0.pdf>Threshold optimization for multi label classifiers</a>‚Äù. The proposed algorithm for solving this optimization problem can be seen in the pseudo code-below:.</p><p>¬†
<img loading=lazy src=/images/optimisation-algorithm.png#center alt=optimisation-algorithm>
¬†</p><p>This algorithm effectively attends one label at a time and tries all possible thresholds for that label to find the threshold with the best micro f1. It does that iteratively (since a decision for one threshold might influence another) until no better threshold can be found for any label. Below is a naive implementation in python.</p><p>¬†
<img loading=lazy src=/images/optimisation-algorithm-implementation.png#center alt=optimisation-algorithm-implementation>
<a href=https://github.com/nsorros/threshold_optimizer/blob/4d468f4da22d6586ca8699b8aaddd6f4caea84d8/optimize_threshold.py>https://github.com/nsorros/threshold_optimizer/blob/4d468f4da22d6586ca8699b8aaddd6f4caea84d8/optimize_threshold.py</a>
¬†</p><p>The code closely follows the pseudo code in the paper with the addition of the nb-thresholds parameter to limit the number of thresholds to scan thereby decoupling the run time from the dataset size used. Running this algorithm on two randomly sparse matrices takes 30s per label. This makes it prohibitively expensive for large label spaces, for example: assuming we need three iterations for the algorithm to converge and we are working with 30k labels it would take 30s x 30,000 x 3 ~ 31 days!</p><p>Since we can‚Äôt usually wait 31 days just to decide which labels to apply after prediction, we needed to find a way to speed up this algorithm. The rest of this blog post focuses on just this problem. We‚Äôll be using a tool called <a href=https://github.com/pyutils/line_profiler>line_profiler</a> to inspect the slow moving parts of the algorithm and work towards making it faster.</p><p>Line profiler was brought to my attention from the excellent book <a href=https://www.amazon.com/High-Performance-Python-Performant-Programming/dp/1492055026>High performance python</a> by <a href=https://twitter.com/ianozsvald>Ian Ozvald</a> and <a href=https://twitter.com/mynameisfiber>Micha Gorelick</a>, which I highly recommend if you want to speed up your python code. All we need to do is install the line profiler <code>pip install liner_profiler</code> and add the <code>@profile</code> decorator in the functions we want to profile. Running our algorithm with it produces the following output:</p><p>¬†
<img loading=lazy src=/images/profiler-1.png#center alt=profiler-1>
¬†
<img loading=lazy src=/images/profiler-2.png#center alt=profiler-2>
¬†</p><p>As we can see most of the time is being spent inside the sklearn function f1_score. If we go ahead and profile it by adding the @profile decorator in the argmax function we get:</p><p>¬†
<img loading=lazy src=/images/profiler-argmax-sklearn.png#center alt=profiler-argmax-sklearn>
¬†</p><p>As it turns out, half of the time is being spent on checking that the data being passed are correct (see line 1547). This is super helpful in most cases, as it will throw an error if the data or flags do not make sense, but quite inefficient in our case, as we constantly pass the same data. Since we cannot disable this behavior we can simply write our own f1_score function.</p><p>¬†
<img loading=lazy src=/images/custom-f1.png#center alt=custom-f1>
<a href=https://github.com/nsorros/threshold_optimizer/blob/2a3d198d3338de3c58437d154bafe9e07dd837a2/optimize_threshold.py>https://github.com/nsorros/threshold_optimizer/blob/2a3d198d3338de3c58437d154bafe9e07dd837a2/optimize_threshold.py</a>
¬†</p><p>This reduces runtime to 17s per label which is half our first attempt but still quite slow. If we profile again we get</p><p>¬†
<img loading=lazy src=/images/custom-f1.png#center alt=profile-custom-f1>
¬†</p><p>In line 17, we see that we seem to have shifted the weight to sklearn‚Äôs multilabel_confusion_matrix. Let‚Äôs profile the multilabel_confusion_matrix function by adding the @profile decorator in the internal of sklearn‚Äôs code. You can find the location where site-packages are installed by running python -m site. The multilabel confusion matrix leaves in _classification.py inside metrics, full path sklearn/metrics/_classification.py.</p><p>¬†
<img loading=lazy src=/images/profile-multilabel-confusion-sklearn.png#center alt=profile-multilabel-confusion-sklearn>
¬†</p><p>We run into the same problem of spending most of the time checking that the y variables are correct, see line 483. Once more we can write our own implementation to avoid the checks.</p><p>¬†
<img loading=lazy src=/images/custom-multilabel-confusion.png#center alt=custom-multilabel-confusion>
<a href=https://github.com/nsorros/threshold_optimizer/commit/7df2d45cda077662f2846a80edbce0c8a0383161>https://github.com/nsorros/threshold_optimizer/commit/7df2d45cda077662f2846a80edbce0c8a0383161</a>
¬†</p><p>Using our own multilabel confusion matrix further reduces the time to 3s which is a 10x improvement so far. Let‚Äôs see what‚Äôs slowing us down now.</p><p>¬†
<img loading=lazy src=/images/profile-custom-multilabel-confusion.png#center alt=profile-custom-multilabel-confusion>
¬†</p><p>We can see that most of the time is being spent in the element-wise multiplication of two large sparse matrices. There is an inefficiency here which is not obvious at first glance: the multilabel confusion matrix recalculates a confusion matrix for each label even though we only alter the threshold for one label. A much more efficient way would be to calculate the multilabel confusion matrix outside this function and ultimately the for loop across labels and only change the entry for the label we explore. This requires us to calculate only one confusion matrix and I think at this point it is obvious that we are better off writing our own implementation.</p><p>¬†
<img loading=lazy src=/images/custom-confusion-matrix.png#center alt=custom-confusion-matrix>
<a href=https://github.com/nsorros/threshold_optimizer/commit/7df2d45cda077662f2846a80edbce0c8a0383161>https://github.com/nsorros/threshold_optimizer/commit/7df2d45cda077662f2846a80edbce0c8a0383161</a>
¬†</p><p>At this point our algorithm takes 0.46s per label which is a 65x speedup. In fact the whole optimization can finish in 5 hours which is acceptable. But, can we do better?</p><p>¬†
<img loading=lazy src=/images/profile-custom-confusion-matrix.png#center alt=profile-custom-confusion-matrix>
¬†</p><p>A seemingly simple operation of choosing the relevant column, lines 31‚Äì32, seems to add up to a significant cost when running multiple times. Since those columns remain the same for the duration of trying different thresholds for one label inside argmax, we can easily improve by picking those columns before calling argmaxf1 and passing them in.
¬†
<img loading=lazy src=/images/optimisation-select-columns.png#center alt=optimisation-select-columns>
<a href=https://github.com/nsorros/threshold_optimizer/commit/d8a2b8755bc244c22e8a1758b06ab597c6fff2db>https://github.com/nsorros/threshold_optimizer/commit/d8a2b8755bc244c22e8a1758b06ab597c6fff2db</a>
¬†</p><p>This change reduces the time to 0.17s per label which is a 176x speedup. This is beginning to be fast üí® but let‚Äôs see if we can push it further.</p><p>¬†
<img loading=lazy src=/images/profile-select-columns.png#center alt=profile-select-columns>
¬†</p><p>Every time we update the thresholds we recalculate the multilabel confusion matrix, line 87, and this is quite expensive. We can employ the same trick we did earlier inside f where we calculate only the confusion matrix that changes.</p><p>¬†
<img loading=lazy src=/images/optimisation-confusion-recalculation.png alt=optimisation-confusion-recalculation>
<a href=https://github.com/nsorros/threshold_optimizer/commit/06cb7a127366aa9844b010e666f5e99190987a64>https://github.com/nsorros/threshold_optimizer/commit/06cb7a127366aa9844b010e666f5e99190987a64</a>
¬†</p><p>This takes us down to 0.02s per label which offers another 10x speedup for a total of 1500x. We could call it a day but let‚Äôs see if there is any other easy win.</p><p>¬†
<img loading=lazy src=/images/final-profile.png alt=final-profile>
¬†</p><p>We can see that a lot of time is being spent on selecting a column of a sparse matrix, lines 78‚Äì79. As it turns out these matrices are in CSR format which is quite efficient for a lot of common data science operations but not for selecting columns</p><p>¬†
<img loading=lazy src=/images/sparse-formats.png alt=sparse-formats>
¬†</p><p>Fortunately for us we can simply convert to CSC in load time and not have to worry about it moving on.</p><p>¬†
<img loading=lazy src=/images/optimisation-sparse.png alt=optimisation-sparse>
<a href=https://github.com/nsorros/threshold_optimizer/commit/06cb7a127366aa9844b010e666f5e99190987a64>https://github.com/nsorros/threshold_optimizer/commit/06cb7a127366aa9844b010e666f5e99190987a64</a>
¬†</p><p>This switch makes the algorithm run on 0.003s per label which gives us a 10k final speedup. The whole algorithm will take approximately 5 minutes for 30k labels and a few hours for millions of labels which is super fast for the problem at hand. We can stop here but it‚Äôs worth saying that we have reached a limit of diminishing returns if we continue. Most of the time is being spent on highly optimized functions in numpy and scipy and even if we write our own and compile them with numba we will not manage to go any faster.</p><p>This blog has walked through the problem of how to optimize a naive implementation of an algorithm. Whilst the starting problem is not relevant to everyone, the techniques which I have used to speed up the implementation are super powerful, and can be applied to any problem.</p><p>You can find the whole code in this repository <a href=https://github.com/nsorros/threshold_optimizer>https://github.com/nsorros/threshold_optimizer</a> and you can also follow the first 8 commits which introduce these changes.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://nsorros.github.io/tags/optimisation/>optimisation</a></li><li><a href=https://nsorros.github.io/tags/multilabel-classification/>multilabel classification</a></li></ul><nav class=paginav><a class=next href=https://nsorros.github.io/posts/tagging-biomedical-grants/><span class=title>Next ¬ª</span><br><span>Tagging biomedical grants with 29K tags</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://nsorros.github.io>Nick Sorros</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>