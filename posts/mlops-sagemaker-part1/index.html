<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>MLOps with SageMaker — Part I | Nick Sorros</title><meta name=keywords content="machine learning,transformers,sagemaker"><meta name=description content="How to effortlessly train sklearn 📊, pytorch🔥, and transformers 🤗 models in the cloud SageMaker is a Machine Learning Operations (MLOps) platform, offered by AWS, that provides a number of tools for developing machine learning models from no code solutions to completely custom. With SageMaker, you can label data, train your own models in the cloud using hyperparameter optimization, and then deploy those models easily behind a cloud hosted API. In this series of posts we will explore SageMaker’s services and provide guides on how to use them, along with code examples."><meta name=author content><link rel=canonical href=https://nsorros.github.io/posts/mlops-sagemaker-part1/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nsorros.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nsorros.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nsorros.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://nsorros.github.io/apple-touch-icon.png><link rel=mask-icon href=https://nsorros.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="MLOps with SageMaker — Part I"><meta property="og:description" content="How to effortlessly train sklearn 📊, pytorch🔥, and transformers 🤗 models in the cloud SageMaker is a Machine Learning Operations (MLOps) platform, offered by AWS, that provides a number of tools for developing machine learning models from no code solutions to completely custom. With SageMaker, you can label data, train your own models in the cloud using hyperparameter optimization, and then deploy those models easily behind a cloud hosted API. In this series of posts we will explore SageMaker’s services and provide guides on how to use them, along with code examples."><meta property="og:type" content="article"><meta property="og:url" content="https://nsorros.github.io/posts/mlops-sagemaker-part1/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-04T10:10:30+03:00"><meta property="article:modified_time" content="2022-05-04T10:10:30+03:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="MLOps with SageMaker — Part I"><meta name=twitter:description content="How to effortlessly train sklearn 📊, pytorch🔥, and transformers 🤗 models in the cloud SageMaker is a Machine Learning Operations (MLOps) platform, offered by AWS, that provides a number of tools for developing machine learning models from no code solutions to completely custom. With SageMaker, you can label data, train your own models in the cloud using hyperparameter optimization, and then deploy those models easily behind a cloud hosted API. In this series of posts we will explore SageMaker’s services and provide guides on how to use them, along with code examples."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://nsorros.github.io/posts/"},{"@type":"ListItem","position":3,"name":"MLOps with SageMaker — Part I","item":"https://nsorros.github.io/posts/mlops-sagemaker-part1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"MLOps with SageMaker — Part I","name":"MLOps with SageMaker — Part I","description":"How to effortlessly train sklearn 📊, pytorch🔥, and transformers 🤗 models in the cloud SageMaker is a Machine Learning Operations (MLOps) platform, offered by AWS, that provides a number of tools for developing machine learning models from no code solutions to completely custom. With SageMaker, you can label data, train your own models in the cloud using hyperparameter optimization, and then deploy those models easily behind a cloud hosted API. In this series of posts we will explore SageMaker’s services and provide guides on how to use them, along with code examples.","keywords":["machine learning","transformers","sagemaker"],"articleBody":"How to effortlessly train sklearn 📊, pytorch🔥, and transformers 🤗 models in the cloud SageMaker is a Machine Learning Operations (MLOps) platform, offered by AWS, that provides a number of tools for developing machine learning models from no code solutions to completely custom. With SageMaker, you can label data, train your own models in the cloud using hyperparameter optimization, and then deploy those models easily behind a cloud hosted API. In this series of posts we will explore SageMaker’s services and provide guides on how to use them, along with code examples. In this first post we will touch on training models using popular frameworks such as sklearn, pytorch and transformers for which Sagemaker provides pre-configured containers.\nWe will be working with a minimal project structure:\nMost of the code for training models, preprocessing data or making predictions should live in src and be well tested. The scripts folder is reserved for automating tasks which might otherwise be done manually with few commands or lines of code. We will also use the scripts folder to store the scripts necessary to run your code on SageMaker.\nThe main library we need is sagemaker (which can be installed from pip as usual) but I am also going to be using typer for adding command line tool (CLI) functionality to my scripts. Other than those I will only use tqdm for adding progress bars, black for formatting and pytest for tests. All this is on top of the framework you want to experiment with, which in my case also includes pytorch, transformers, and sklearn.\nThe data I will be using comes from a sentiment classification task on Kaggle. The data comes in CSV format and contains two columns, text and label. The label is either 0 or 1.\nBelow is a simple training script in sklearn that trains a tf-idf svm pipeline using that data.\nThe script is vanilla sklearn. The only alteration for sagemaker is to set the default data_path and model_path. We can use this script outside sagemaker without any problem by passing a path to our data and models folder. Let’s run it\nBefore we explain the default values for model and data path let’s also write the script that will trigger the sagemaker job.\nThat’s it. We can now run this script by passing a path to our local data and models folder and it will download the container locally and run it.\n![run-sagemaker-sklearn(/images/run-sagemaker-sklearn.png#center) If we now change the instance type to one of the instances SageMaker works with (complete list here) and pass an s3 path to our data and models folder, the training will happen in the cloud.\nOne thing to note is that the data and model path needs to be prepended either with file:// or s3:// depending on whether you want to read from a local directory or s3.\nIn order for SageMaker to work, you need to have a role with appropriate permissions. You can read more on how to create that here. Here is also a terraform manifest that my co-founder Matt has written which might be helpful to set up. It is important to ensure the role has permissions to read and write in s3 in order to read the data and write the model. In this script we pass the role via a command line argument which by default reads it from an environment variable.\nWhat’s going on under the hood is that sagemaker uses a preconfigured container with sklearn installed. We instruct sagemaker to use that container by using the SKLearn class. The version of sklearn is defined by the parameter framework_version, so in this example it is 0.20, and it is advised to have the same version in your requirements.txt to ensure a smooth experience. Currently sagemaker provides containers with version 0.20 and 0.23 but not 1.0+.\nOur training script defined in the entry_point is copied inside the container. Note that our training script only uses the standard library and scikit-learn. If it was using a library not present in the container, SageMaker would throw an error. This is why we opted for argparse instead of typer for passing command line arguments to that script. We can define additional dependencies that will be installed in the container but let’s leave that for the next blog.\nThe data passed as a parameter is also copied inside the container inside a predefined location. This location is passed as the environment variable SM_CHANNEL_TRAIN. Similarly, there is a predefined location that sagemaker will look for the model in order to copy it outside the container. This location is also passed as an environment variable, SM_MODEL_DIR. Note that SageMaker does not copy your data to s3 automatically so this is something you need to do if the data is not there already. Lastly, the hyperparameters provided will get passed as command line arguments into our training script. As such they need to have the same name as the command line arguments in the training script. Even though not strictly required, we also pass a job_name to more easily retrieve the logs and the model afterwards.\nSwitching to a different framework should be straightforward as most of the code to trigger the SageMaker job was framework agnostic. Here is the equivalent script for PyTorch.\nWe have to switch to using the PyTorch class that takes similar arguments. The only other things that change are the hyperparameters, framework_version and the job_name_prefix. Currently, the latest pytorch version supported is 0.10. We also need to provide a valid python version, which now is py38, so once more it is advisable to be running python3.8 locally to ensure your code is compatible. Our entry_point targets a pytorch training script which you can find here.\nFinally, let’s switch to transformers:\nAs previously, we need to import the right class which in this case is HuggingFace. We need to provide appropriate versions for our main libraries pytorch and transformers. The latest transformers version supported at time of writing is 4.12. Our hyperparameters are also specific to the training script which you can find here.\nAs we mentioned, uploading your data to s3 is also necessary to get sagemaker working. It may be that your data is already there. If not, there are a couple of ways you can upload them including awscli with aws s3 cp. SageMaker also provides a convenient function that allows you to upload single files or entire folders in a predefined location. Here it is wrapped in a script.\nYou may also want to download the trained model locally. There is another function that allows you to download file(s) from s3. Here it is, also wrapped in a script.\nNote that we introduce an optional parameter job_name. This is because SageMaker does not only save the model in the model_path but also some other information like logs. If we simply want to download the model, this is stored inside job_name/output which is one of the reasons we want to have control of the job name instead of having it auto generated.\nFinally, when you kick off a job with sagemaker, it streams the logs produced by default. Some of those jobs though will need some time to finish so you need a way to access the logs at random intervals. You can easily do that via another SageMaker command, like here:\nThe wait parameter provides logs in a streaming fashion as we would see them in the terminal if we were running the script locally. We can interrupt at any point without killing the job.\nThese are all the additional scripts we added to work with SageMaker\nYou can find the complete code inside this repository https://github.com/MantisAI/sagemaker_examples, including the training scripts for pytorch and transformers.\nIn this post we set the scene on how to use SageMaker to train your models. We started by using its pre configured framework containers which easily allow you to run your script in the cloud. We also created some helper scripts to upload data and download models as well as see logs to be able to work with and monitor a SageMaker job.\nIn our next post we will explore how we can customize our training by including additional libraries, bringing additional scripts and building our own containers. We will then explore inference with SageMaker. Stay tuned.\n","wordCount":"1386","inLanguage":"en","datePublished":"2022-05-04T10:10:30+03:00","dateModified":"2022-05-04T10:10:30+03:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://nsorros.github.io/posts/mlops-sagemaker-part1/"},"publisher":{"@type":"Organization","name":"Nick Sorros","logo":{"@type":"ImageObject","url":"https://nsorros.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nsorros.github.io accesskey=h title="Nick Sorros (Alt + H)">Nick Sorros</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nsorros.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nsorros.github.io>Home</a>&nbsp;»&nbsp;<a href=https://nsorros.github.io/posts/>Posts</a></div><h1 class=post-title>MLOps with SageMaker — Part I</h1><div class=post-meta><span title='2022-05-04 10:10:30 +0300 +0300'>May 4, 2022</span>&nbsp;·&nbsp;7 min</div></header><div class=post-content><h2 id=how-to-effortlessly-train-sklearn--pytorch-and-transformers--models-in-the-cloud>How to effortlessly train sklearn 📊, pytorch🔥, and transformers 🤗 models in the cloud<a hidden class=anchor aria-hidden=true href=#how-to-effortlessly-train-sklearn--pytorch-and-transformers--models-in-the-cloud>#</a></h2><p><a href=https://aws.amazon.com/sagemaker/>SageMaker</a> is a Machine Learning Operations (MLOps) platform, offered by AWS, that provides a number of tools for developing machine learning models from no code solutions to completely custom. With SageMaker, you can label data, train your own models in the cloud using hyperparameter optimization, and then deploy those models easily behind a cloud hosted API. In this series of posts we will explore SageMaker’s services and provide guides on how to use them, along with code examples. In this first post we will touch on training models using popular frameworks such as sklearn, pytorch and transformers for which Sagemaker provides pre-configured containers.</p><p>We will be working with a minimal project structure:</p><p> 
<img loading=lazy src=/images/project-structure.png#center alt=project-structure>
 </p><p>Most of the code for training models, preprocessing data or making predictions should live in <code>src</code> and be well tested. The <code>scripts</code> folder is reserved for automating tasks which might otherwise be done manually with few commands or lines of code. We will also use the scripts folder to store the scripts necessary to run your code on SageMaker.</p><p>The main library we need is <code>sagemaker</code> (which can be installed from pip as usual) but I am also going to be using typer for adding command line tool (CLI) functionality to my scripts. Other than those I will only use tqdm for adding progress bars, <code>black</code> for formatting and <code>pytest</code> for tests. All this is on top of the framework you want to experiment with, which in my case also includes <code>pytorch</code>, <code>transformers</code>, and <code>sklearn</code>.</p><p>The data I will be using comes from a <a href=https://www.kaggle.com/yasserh/imdb-movie-ratings-sentiment-analysis>sentiment classification task</a> on Kaggle. The data comes in CSV format and contains two columns, text and label. The label is either 0 or 1.</p><p>Below is a simple training script in sklearn that trains a <code>tf-idf svm</code> pipeline using that data.</p><p> 
<img loading=lazy src=/images/tfidf-svm-script.png#center alt=tfidf-svm-script>
 </p><p>The script is vanilla <code>sklearn</code>. The only alteration for sagemaker is to set the default <code>data_path</code> and <code>model_path</code>. We can use this script outside sagemaker without any problem by passing a path to our data and models folder. Let’s run it</p><p> 
<img loading=lazy src=/images/run-train-sklearn.png#center alt=run-train-sklearn>
 </p><p>Before we explain the default values for model and data path let’s also write the script that will trigger the sagemaker job.</p><p> 
<img loading=lazy src=/images/sagemaker-sklearn-train.png#center alt=sagemaker-sklearn-train>
 </p><p>That’s it. We can now run this script by passing a path to our local data and models folder and it will download the container locally and run it.</p><p> 
![run-sagemaker-sklearn(/images/run-sagemaker-sklearn.png#center)
 </p><p>If we now change the instance type to one of the instances SageMaker works with (complete list <a href=https://aws.amazon.com/sagemaker/pricing/>here</a>) and pass an s3 path to our data and models folder, the training will happen in the cloud.</p><p> 
<img loading=lazy src=/images/run-sklearn-sagemaker-cloud.png alt=run-sklearn-sagemaker-cloud>
 </p><p>One thing to note is that the data and model path needs to be prepended either with <code>file://</code> or <code>s3://</code> depending on whether you want to read from a local directory or s3.</p><p>In order for SageMaker to work, you need to have a role with appropriate permissions. You can read more on how to create that <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html,>here</a>. Here is also a <a href=https://github.com/MantisAI/sagemaker-test/blob/master/terraform/sagemaker_test.tf>terraform manifest</a> that my co-founder <a href=https://twitter.com/m_a_upson>Matt</a> has written which might be helpful to set up. It is important to ensure the role has permissions to read and write in s3 in order to read the data and write the model. In this script we pass the role via a command line argument which by default reads it from an environment variable.</p><p>What’s going on under the hood is that sagemaker uses a preconfigured container with sklearn installed. We instruct sagemaker to use that container by using the <code>SKLearn</code> class. The version of <code>sklearn</code> is defined by the parameter <code>framework_version</code>, so in this example it is <code>0.20</code>, and it is advised to have the same version in your <code>requirements.txt</code> to ensure a smooth experience. Currently sagemaker provides containers with version <code>0.20</code> and <code>0.23</code> but not <code>1.0+</code>.</p><p>Our training script defined in the <code>entry_point</code> is copied inside the container. Note that our training script only uses the standard library and <code>scikit-learn</code>. If it was using a library not present in the container, SageMaker would throw an error. This is why we opted for <code>argparse</code> instead of <code>typer</code> for passing command line arguments to that script. We can define additional dependencies that will be installed in the container but let’s leave that for the next blog.</p><p>The data passed as a parameter is also copied inside the container inside a predefined location. This location is passed as the environment variable <code>SM_CHANNEL_TRAIN</code>. Similarly, there is a predefined location that sagemaker will look for the model in order to copy it outside the container. This location is also passed as an environment variable, <code>SM_MODEL_DIR</code>. Note that SageMaker does not copy your data to s3 automatically so this is something you need to do if the data is not there already. Lastly, the hyperparameters provided will get passed as command line arguments into our training script. As such they need to have the same name as the command line arguments in the training script. Even though not strictly required, we also pass a <code>job_name</code> to more easily retrieve the logs and the model afterwards.</p><p>Switching to a different framework should be straightforward as most of the code to trigger the SageMaker job was framework agnostic. Here is the equivalent script for PyTorch.</p><p> 
<img loading=lazy src=/images/pytorch-script.png#center alt=pytorch-script>
 </p><p>We have to switch to using the <code>PyTorch</code> class that takes similar arguments. The only other things that change are the <code>hyperparameters</code>, <code>framework_version</code> and the <code>job_name_prefix</code>. Currently, the latest pytorch version supported is <code>0.10</code>. We also need to provide a valid python version, which now is <code>py38</code>, so once more it is advisable to be running python3.8 locally to ensure your code is compatible. Our <code>entry_point</code> targets a pytorch training script which you can find <a href=https://github.com/MantisAI/sagemaker_examples/blob/main/src/train_pytorch.py>here</a>.</p><p>Finally, let’s switch to transformers:</p><p> 
<img loading=lazy src=/images/transformers-script.png#center alt=transformers-script>
 </p><p>As previously, we need to import the right class which in this case is <code>HuggingFace</code>. We need to provide appropriate versions for our main libraries pytorch and transformers. The latest transformers version supported at time of writing is <code>4.12</code>. Our hyperparameters are also specific to the training script which you can find <a href=https://github.com/MantisAI/sagemaker_examples/blob/main/src/train_transformers.py>here</a>.</p><p>As we mentioned, uploading your data to s3 is also necessary to get sagemaker working. It may be that your data is already there. If not, there are a couple of ways you can upload them including <code>awscli</code> with <code>aws s3 cp</code>. SageMaker also provides a convenient function that allows you to upload single files or entire folders in a predefined location. Here it is wrapped in a script.</p><p> 
<img loading=lazy src=/images/upload-data.png#center alt=upload-data>
 </p><p>You may also want to download the trained model locally. There is another function that allows you to download file(s) from s3. Here it is, also wrapped in a script.</p><p> 
<img loading=lazy src=/images/download-model.png#center alt=download-model>
 </p><p>Note that we introduce an optional parameter <code>job_name</code>. This is because SageMaker does not only save the model in the <code>model_path</code> but also some other information like logs. If we simply want to download the model, this is stored inside <code>job_name/output</code> which is one of the reasons we want to have control of the job name instead of having it auto generated.</p><p>Finally, when you kick off a job with sagemaker, it streams the logs produced by default. Some of those jobs though will need some time to finish so you need a way to access the logs at random intervals. You can easily do that via another SageMaker command, like here:</p><p> 
<img loading=lazy src=/images/get-logs.png#center alt=get-logs>
 </p><p>The wait parameter provides logs in a streaming fashion as we would see them in the terminal if we were running the script locally. We can interrupt at any point without killing the job.</p><p>These are all the additional scripts we added to work with SageMaker</p><p> 
<img loading=lazy src=/images/scripts-tree.png#center alt=scripts-tree>
 </p><p>You can find the complete code inside this repository <a href=https://github.com/MantisAI/sagemaker_examples>https://github.com/MantisAI/sagemaker_examples</a>, including the training scripts for pytorch and transformers.</p><p>In this post we set the scene on how to use SageMaker to train your models. We started by using its pre configured framework containers which easily allow you to run your script in the cloud. We also created some helper scripts to upload data and download models as well as see logs to be able to work with and monitor a SageMaker job.</p><p>In our next post we will explore how we can customize our training by including additional libraries, bringing additional scripts and building our own containers. We will then explore inference with SageMaker. Stay tuned.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://nsorros.github.io/tags/machine-learning/>machine learning</a></li><li><a href=https://nsorros.github.io/tags/transformers/>transformers</a></li><li><a href=https://nsorros.github.io/tags/sagemaker/>sagemaker</a></li></ul><nav class=paginav><a class=prev href=https://nsorros.github.io/posts/mlops-sagemaker-part2/><span class=title>« Prev</span><br><span>MLOps with SageMaker — Part II</span></a>
<a class=next href=https://nsorros.github.io/posts/optimisation-10k-faster/><span class=title>Next »</span><br><span>Making an optimisation algorithm 10k times faster 🏎</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://nsorros.github.io>Nick Sorros</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>